{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25901995",
   "metadata": {},
   "source": [
    "# This is the Tensor Train stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 18 15:13:52 2022\n",
    "\n",
    "@author: alielmoselhy\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy import einsum, sqrt, dot, array, nonzero, nancumsum, nansum\n",
    "from numpy import exp, dot, linalg, arange, log10, array, sqrt, diff, random\n",
    "from numpy import zeros,nan\n",
    "from numpy.random import randn,rand\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "\n",
    "\n",
    "from numpy.linalg.linalg import solve\n",
    "\n",
    "#import numba\n",
    "import pandas as pd\n",
    "\n",
    "def factorial(n):\n",
    "    if n<0:\n",
    "        print(\"This is wrong. Negative factorial\")\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        y = 1\n",
    "        for i in range(1,n+1):\n",
    "            y *= i\n",
    "        return y*1.0\n",
    "    \n",
    "def initialize_analysis(max_order, output_field, dataset, demean=True):\n",
    "    # Y is the output\n",
    "    # X are the points of dimension MC, numModes\n",
    "    # W is ones size of Y\n",
    "    #df = pd.read_csv('final_data.csv')\n",
    "    #X = df[['ART', 'PrEP', 'VMMC']].values\n",
    "    \n",
    "    \n",
    "    #df = pd.read_csv('./all_points_42.csv')\n",
    "    #df = pd.read_csv('./dummy_func.csv')\n",
    "\n",
    "    \n",
    "    #print(df.shape)\n",
    "    #df = df[['PresProb','Child_6w', 'TestUptake', 'Staging', \n",
    "    #         'PreART', 'FastART','On_ART', 'KeepART', 'ARTInterrupted',  \n",
    "    #         'PrEP', 'VMMC', 'Cost', 'DALY']]\n",
    "    \n",
    "    # We may want to change the order of the input columns\n",
    "    #df = df.groupby(['ART','PrEP', 'VMMC']).mean().reset_index()\n",
    "    # df = df.sample(10000)\n",
    "    \n",
    "    #if demean:\n",
    "    #    df = dataset.groupby(list(dataset.columns[:-2].values)).mean().reset_index()\n",
    "    #if not demean:    \n",
    "    #    M = int(len(df)/2)\n",
    "    #    df = dataset.sample(M)\n",
    "    df = dataset\n",
    "    X = df[df.columns[:-2].values].values #- 0.5\n",
    "    Y = df[output_field].values\n",
    "    \"\"\"\n",
    "    X = df[df.columns[:-1].values].values #- 0.5\n",
    "    Y = df[df.columns[-1]].values\n",
    "    \"\"\"\n",
    "    #Y = df['Cost'].values\n",
    "    W = Y**0.0\n",
    "    #H = get_taylor_polynomial(X, max_order)\n",
    "    H = get_orthogonal_polynomial(X, max_order)\n",
    "    return X,Y,H,W\n",
    "\n",
    "\n",
    "\n",
    "def get_orthogonal_polynomial(P, max_order):\n",
    "    #print(P.shape)\n",
    "    MC, numModes = P.shape\n",
    "    H = np.zeros((MC, numModes, max_order))\n",
    "    H[:,:,0] = 1\n",
    "    H[:,:,1] = P\n",
    "    for n in range(2,max_order):\n",
    "        H[:,:, n] = P**n\n",
    "    for n in range(2,max_order):\n",
    "        # print([n, factorial(n)])\n",
    "        H[:,:, n] = H[:,:, n]/factorial(n)\n",
    "\n",
    "    return H\n",
    "\n",
    "def get_dH(P, max_order):\n",
    "    MC, numModes = P.shape\n",
    "    dH = np.zeros((MC, numModes, max_order))\n",
    "    #print(P.shape)\n",
    "    dH[:,:,0] = 0\n",
    "    dH[:,:,1] = 1\n",
    "    for n in range(2,max_order):\n",
    "        dH[:,:, n] = n * P**(n-1)\n",
    "    for n in range(2,max_order):\n",
    "        # print([n, factorial(n)])\n",
    "        dH[:,:, n] = dH[:,:, n]/factorial(n)\n",
    "    return dH\n",
    "\n",
    "def get_d2H(P, max_order):\n",
    "    MC, numModes = P.shape\n",
    "    d2H = np.zeros((MC, numModes, max_order))\n",
    "    d2H[:,:,0] = 0\n",
    "    d2H[:,:,1] = 0\n",
    "    for n in range(2,max_order):\n",
    "        d2H[:,:, n] = n * (n-1) * P**(n-2)\n",
    "    for n in range(2,max_order):\n",
    "        # print([n, factorial(n)])\n",
    "        d2H[:,:, n] = d2H[:,:, n]/factorial(n)\n",
    "    return d2H\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def normalize_H(dxH):\n",
    "#    for n in range(2,dxH.shape[2]):\n",
    "#        # print([n, factorial(n)])\n",
    "#        H[:,:, n] = H[:,:, n]/np.sqrt(factorial(n))\n",
    "\n",
    "    \n",
    "def fillLeftInterpolation(left_index, max_order, tt_rank, GC, H):\n",
    "    '''\n",
    "    Can I make these much faster\n",
    "    U is MC * left rank\n",
    "    GC[i] is r1,r2,max_order\n",
    "    H is MC, numModes, max_order\n",
    "    '''\n",
    "    # the below dimensions should be asserted\n",
    "    MC = H.shape[0]\n",
    "    U = np.ones((MC, 1))\n",
    "    for i in range(left_index):\n",
    "        # G = np.zeros((tt_rank[i]))\n",
    "        G = einsum('ijk,Nk->Nij', GC[i], H[:,i])\n",
    "        #print(G.shape)\n",
    "        U = einsum('Ni,Nij->Nj', U, G)\n",
    "        #print(U.shape)\n",
    "        # if you want you can store the G\n",
    "    #print(U.shape)\n",
    "    #if left_index>3:\n",
    "    #    bla\n",
    "    return U\n",
    "        \n",
    "\n",
    "def fillRightInterpolation(right_index, max_order, tt_rank, GC, H, num_tensors):\n",
    "    '''\n",
    "    Can I make these much faster\n",
    "    '''\n",
    "    # the below dimensions should be asserted\n",
    "    MC = H.shape[0]\n",
    "    V = np.ones((1, MC))\n",
    "    #print(V.shape)\n",
    "    for i in range(num_tensors-1,right_index,-1):\n",
    "        # G = np.zeros((tt_rank[i]))\n",
    "        G = einsum('ijk,Nk->Nij', GC[i], H[:,i])\n",
    "        #print(G.shape)\n",
    "        V = einsum('Nij,jN->iN', G, V)\n",
    "        #print(V.shape)\n",
    "        # if you want you can store the G\n",
    "    #print(V.shape)\n",
    "    #if right_index>3:\n",
    "    #    bal\n",
    "    return V\n",
    "\n",
    "def fillCoreBasis_smart(left_index, right_index, H):\n",
    "    # the below dimensions should be asserted\n",
    "    MC, numModes, max_order = H.shape\n",
    "    B = einsum('Ni,Nj->Nij', H[:, left_index], H[:, right_index])\n",
    "    return B\n",
    "\n",
    "def fillCoreBasis_dumb(left_index, right_index, H):\n",
    "    # the below dimensions should be asserted\n",
    "    MC, numModes, max_order = H.shape\n",
    "    B = H[:, left_index]\n",
    "    return B\n",
    "\n",
    "def evaluate_tt_on_grid(GC, H):\n",
    "    '''\n",
    "    Can I make these much faster\n",
    "    U is MC * left rank\n",
    "    GC[i] is r1,r2,max_order\n",
    "    H is MC, numModes, max_order\n",
    "    '''\n",
    "    # the below dimensions should be asserted\n",
    "    num_tensors = len(GC)\n",
    "    MC = H.shape[0]\n",
    "    U = np.ones((MC, 1))\n",
    "    for i in range(num_tensors):\n",
    "        # G = np.zeros((tt_rank[i]))\n",
    "        G = einsum('ijk,Nk->Nij', GC[i], H[:,i]) # .clip(-10,10), I am not sure clipping makes any sense\n",
    "        U = einsum('Ni,Nij->Nj', U, G)\n",
    "        #print(U.shape)\n",
    "    return U[:,0]\n",
    "\n",
    "\n",
    "\n",
    "def initialize_train(numModes, initial_rank, max_order):\n",
    "    GC = {}\n",
    "    tt_rank = {}\n",
    "    #GC[0] = rand(1, initial_rank, max_order)\n",
    "    GC[0] = np.zeros((1, initial_rank, max_order))\n",
    "    GC[0][0, :, :] = 1.\n",
    "    tt_rank[0] = [1,initial_rank]\n",
    "    for i in range(1, numModes-1):\n",
    "        #GC[i] = rand(initial_rank, initial_rank, max_order)\n",
    "        GC[i] = np.zeros((initial_rank, initial_rank, max_order))\n",
    "        GC[i][:, :, :] = np.eye(initial_rank)[:,:,None]\n",
    "        tt_rank[i] = [initial_rank,initial_rank]\n",
    "    #GC[numModes-1] = rand(initial_rank, 1, max_order)\n",
    "    GC[numModes-1] = np.zeros((initial_rank, 1, max_order))\n",
    "    GC[numModes-1][:, 0, :] = 1.\n",
    "    tt_rank[numModes-1] = [initial_rank,1]\n",
    "    return GC, tt_rank\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def f7_dumb(B, U, V, W, YW, ):\n",
    "    MC, max_order = B.shape \n",
    "    MC, r1 = U.shape\n",
    "    r2, MC = V.shape\n",
    "    #print(U,V,B)\n",
    "    A = B[:, None, None, :] * U[:, :, None, None] * V.T[:, None, :, None]\n",
    "\n",
    "    A = A.reshape(MC, r1 * r2 * max_order)\n",
    "    AW = A * sqrt(W)[:,None]\n",
    "    #ATWTWA = AW.T.dot(AW).reshape(r1*max_order, r3*max_order, r1*max_order, r3*max_order)\n",
    "    #ATWTWY = AW.T.dot(YW).reshape(r1*max_order, r3*max_order)\n",
    " \n",
    "    #return ATWTWA, ATWTWY\n",
    "    return AW, YW\n",
    "\n",
    "\n",
    "def get_A(left_index, right_index, num_tensors, max_order, tt_rank, GC, H, YW, W,):\n",
    "    U = fillLeftInterpolation(left_index, max_order, tt_rank, GC, H)\n",
    "    V = fillRightInterpolation(left_index, max_order, tt_rank, GC, H, num_tensors)\n",
    "    B = fillCoreBasis_dumb(left_index, right_index, H)\n",
    "    MC, r1 = U.shape\n",
    "    r2, MC = V.shape\n",
    "    #print(U.shape)\n",
    "    #bla\n",
    "    MC, max_order = B.shape\n",
    "    AW, YW = f7_dumb(B,U,V, W, YW)\n",
    "    return AW, YW\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "def solve_leastsquares_dumb(\n",
    "         left_index, right_index, num_tensors, max_order, tt_rank, GC, \n",
    "         H, Y, W, max_rank, randomH):\n",
    "     '''\n",
    "     # dimensions of U: MC x r_i-1\n",
    "     # dimensions of V: r_i+1 x MC\n",
    "     # dimensions of B: MC x max_order x max_order\n",
    "     # U[l1, :] * sum(X[i,j] * B[l1,i,j]) * V[:, l1] = Y[l1]\n",
    "     # kron(V[:, l1]^T, U[l1, :])\n",
    "     I need to make this function much faster. Preferably by using the einsum as above\n",
    "     '''\n",
    "     MC = Y.shape[0]\n",
    "     r1 = GC[left_index].shape[0]\n",
    "     r2 = GC[left_index].shape[1]\n",
    "     #r3 = GC[right_index].shape[1]\n",
    "     max_order = GC[left_index].shape[2]\n",
    "     \n",
    "     YW = Y * sqrt(W)\n",
    "     #print(YW, Y, W)\n",
    "\n",
    "     #ATWTWA,ATWTWY = get_AY(left_index, right_index, num_tensors, max_order, tt_rank, GC, H, YW, W, )\n",
    "     #print(H)\n",
    "     AW,YW = get_A(left_index, right_index, num_tensors, max_order, tt_rank, GC, H, YW, W, )\n",
    "     #print(YW)\n",
    "     s = np.zeros((max_rank,))\n",
    "     if True:\n",
    "         #print(r1,r3,max_order)\n",
    "         #print(ATWTWA.shape, ATWTWY.shape)\n",
    "         #x = np.linalg.solve(ATWTWA.reshape(r1*max_order * r3*max_order, r1*max_order * r3*max_order)\n",
    "         #                    + 1e-4 * np.linalg.norm(ATWTWA) * np.eye(r1*max_order * r3*max_order), ATWTWY.reshape(r1*max_order * r3*max_order))\n",
    "         #u,s,v = np.linalg.svd(AW, full_matrices=False)\n",
    "         #ll = np.nonzero(s/s[0]<1e-12)[0][0]\n",
    "         #if not ll:\n",
    "         #    ll = len(s)\n",
    "         #ll = 50\n",
    "         #AWa = (u[:,:ll] * s[:ll]) @ v[:ll]\n",
    "         #print(AW.shape, AWa.shape, ll, s[:3], s[-3:])\n",
    "         #print(AW.shape, AWa.shape, ll)\n",
    "         AWTAW = AW.T @ AW\n",
    "         P = np.diag(AWTAW)\n",
    "         m = P.max()\n",
    "         P = 1/P.clip(m*1e-4, m)\n",
    "         P = np.diag(P)\n",
    "         x = np.linalg.solve(P @ AWTAW + 1e-4 * np.eye(AWTAW.shape[0]),  P @ (AW.T @ YW))\n",
    "         #x = np.linalg.solve(P[None] * AWTAW + 1e-4 * np.eye(AWTAW.shape[0]),  P *  (AW.T @ YW))\n",
    "         \n",
    "         \n",
    "         \n",
    "         #x = np.linalg.lstsq(AW, YW, rcond=1e-6)[0]\n",
    "\n",
    "         #print(AW.shape)\n",
    "         #print(AW)\n",
    "         #print(AW.max(axis = 1))\n",
    "         #print(P)\n",
    "         #print(P.shape)\n",
    "         #print(P @ AW)\n",
    "         #blah\n",
    "         #P = np.diag(1/(AW.max(axis = 1)+1e-2))\n",
    "         #x = np.linalg.lstsq(P @ AW, P @ YW, rcond=1e-6)[0]\n",
    "         \n",
    "         #x = my_lstsq3(GC, max_order, left_index, right_index, num_tensors, tt_rank, AW, YW, randomH)\n",
    "         #print(left_index)\n",
    "        \n",
    "         \n",
    "         \n",
    "         #xr = np.linalg.lstsq(AW[:,:ll], YW)[0]\n",
    "         #x = np.zeros((AW.shape[1]))\n",
    "         #x[:ll] = xr\n",
    "         #blabla\n",
    "         #print(np.linalg.norm(x))\n",
    "         betaL = x.reshape(r1, r2, max_order)\n",
    "         betaR = None\n",
    "     endt = time.time()\n",
    "     return betaL, betaR\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def do_main_iteration(numLoops, num_tensors, max_order, max_rank, tt_rank, GC, H, Y, W):\n",
    "    converged = False\n",
    "    error_norm = np.zeros((numLoops,))\n",
    "    have_time = True\n",
    "    GC0 = GC.copy()\n",
    "    Y_estimated_old = 0 * Y\n",
    "\n",
    "\n",
    "    for dummy in range(numLoops):\n",
    "        #print(\"Loop = %d\"%(dummy))\n",
    "        #print(dummy, (np.linalg.norm(Y-Y_estimated_old)/np.linalg.norm(Y) * 100).round(2))\n",
    "        #print(tt_rank)\n",
    "        # forward and backward pass\n",
    "        als_list = range(num_tensors-1)\n",
    "        als_list = range(num_tensors)\n",
    "        if dummy%2 == 1 and False:\n",
    "            als_list = als_list[::-1]\n",
    "\n",
    "        MC = 50000\n",
    "        randomSamples = np.random.rand(MC, len(GC))\n",
    "        #randomH = get_taylor_polynomial(randomSamples, max_order)\n",
    "        randomH = get_orthogonal_polynomial(randomSamples, max_order)\n",
    "\n",
    "\n",
    "        # do one pass\n",
    "        for left_index in als_list:\n",
    "            #print(\"Sweep %d at cart %d\"%(dummy, left_index))\n",
    "            right_index = left_index + 1\n",
    "            start = time.time()\n",
    "            # this is the outer loop where I move from cart to cart.\n",
    "            # U, V, B, \n",
    "            betaL, betaR = solve_leastsquares_dumb(\n",
    "                    left_index, right_index, num_tensors, max_order, tt_rank, GC, \n",
    "                    H, Y.copy(), W, max_rank, randomH)\n",
    "            GC[left_index] = betaL\n",
    "            #GC[right_index] = betaR\n",
    "            GC0 = GC.copy()\n",
    "            end = time.time()\n",
    "            tt_rank[left_index] = GC[left_index].shape[:2]\n",
    "            #tt_rank[right_index] = GC[right_index].shape[:2]\n",
    "\n",
    "\n",
    "        #print(\"Computing error after update: error, original, estimate, \\n ... + weights\")\n",
    "        Y_estimated = evaluate_tt_on_grid(GC, H)\n",
    "        #print('%f, \\t%f, \\t%f, \\n%f, \\t%f, \\t%f'%(scipy.linalg.norm(Y-Y_estimated), scipy.linalg.norm(Y), scipy.linalg.norm(Y_estimated),\n",
    "        #                                                 scipy.linalg.norm((Y-Y_estimated)*sqrt(W)), \n",
    "        #                                                 scipy.linalg.norm(Y*sqrt(W)), scipy.linalg.norm(Y_estimated*sqrt(W)),))\n",
    "        #print('%f, \\t%f, \\t%f'%(scipy.linalg.norm((Y_estimated_old-Y_estimated)*sqrt(W)), \n",
    "        #                                                 scipy.linalg.norm(Y_estimated_old*sqrt(W)), \n",
    "        #                                                 scipy.linalg.norm(Y_estimated*sqrt(W)),))\n",
    "        #print(\"%s\\n%s\\n\"%(regress(Y, Y_estimated, W),regress(Y, Y_estimated_old, W),))\n",
    "        Y_estimated_old = Y_estimated\n",
    "        \n",
    "\n",
    "\n",
    "        if converged is True:\n",
    "            break\n",
    "    # evaluate the right interpolation\n",
    "    # evaluate the basis of the core\n",
    "    # U, V, B, get the unknowns\n",
    "    # print(GC)\n",
    "    # at this point I have to evaluate the model\n",
    "    Y_estimated = evaluate_tt_on_grid(GC, H)\n",
    "    #print(\"The error is:= \")\n",
    "    #print(scipy.linalg.norm(Y-Y_estimated))\n",
    "    #print(scipy.linalg.norm(Y))\n",
    "    return GC, tt_rank\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(output_field, dataset, max_order=5, initial_rank=3, max_rank = 3, numLoops=15):\n",
    "    '''\n",
    "    This is the code I run on each partition.\n",
    "    func here gives us Y,H,W,D\n",
    "    H is probably the polynomial chaos expansion\n",
    "    \n",
    "    '''\n",
    "\n",
    "    numModes = 8\n",
    "    if max_order is None:\n",
    "        max_order = 5 #this is the discretization\n",
    "    if initial_rank is None:\n",
    "        initial_rank = 1 # this is the initial and the final rank since in this implementation I don't allow the rank to change\n",
    "    if max_rank is None:\n",
    "        max_rank = 4\n",
    "    if numLoops is None:\n",
    "        numLoops = 30\n",
    "\n",
    "\n",
    "    # Y are the samples we are going to fit\n",
    "    # H  are the polynomial chaos expansions at the samples X\n",
    "    # W is the weight, we can use all ones as a start\n",
    "    # D is something I don't remember, probably the dates and we don't need to do anything with them\n",
    "    X,Y,H,W = initialize_analysis(max_order, output_field, dataset, demean=True)\n",
    "    numModes = H.shape[1]\n",
    "    max_order = H.shape[2]\n",
    "    \n",
    "\n",
    "    GC, tt_rank = initialize_train(numModes, initial_rank, max_order)\n",
    "    #print(len(GC))\n",
    "    GC, tt_rank = do_main_iteration(numLoops, numModes, max_order, max_rank, tt_rank, GC, H, Y, W)\n",
    "    Y_estimated = evaluate_tt_on_grid(GC, H)\n",
    "    #regr = regress(Y, Y_estimated, W)\n",
    "    return GC, tt_rank, Y, Y_estimated, W\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475be159",
   "metadata": {},
   "source": [
    "# This is the Newton Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 18 15:16:24 2022\n",
    "\n",
    "@author: alielmoselhy\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# this is the Newton cell\n",
    "\n",
    "def get_utility(X, GC_Const, GC_Obj, const_val, max_order_obj, \n",
    "                max_order_const, upper_factor, lower_factor, \n",
    "                const_factor):\n",
    "\n",
    "    H_obj = get_orthogonal_polynomial(X, max_order_obj)\n",
    "    H_const = get_orthogonal_polynomial(X, max_order_const)\n",
    "    obj = evaluate_tt_on_grid(GC_Obj, H_obj)\n",
    "    est_const = evaluate_tt_on_grid(GC_Const, H_const)\n",
    "    const_penalty = np.exp( (est_const-const_val) / const_factor )\n",
    "    # axis 0: random trajectories\n",
    "    # axis 1: parameters\n",
    "\n",
    "    # X is random trajectories x parameters\n",
    "    lower_bound = np.exp( -X / lower_factor ).sum(axis = 1)\n",
    "    upper_bound = np.exp( (X-1)/ upper_factor ).sum(axis = 1)\n",
    "\n",
    "    #print(\"bound_error =\", upper_bound+lower_bound)\n",
    "    #print(\"const_error =\", const_penalty)\n",
    "    #print(\"Obj_error\", obj)\n",
    "    utility = 1.0*obj + 1.0*const_penalty + 1e2 * (upper_bound + lower_bound) + 0e1 * np.nansum((X - 0.5)**2., axis=1)\n",
    "\n",
    "    return utility, obj, const_penalty, upper_bound, lower_bound\n",
    "\n",
    "\n",
    "def linesearch(X, dx, GC_Const, GC_Obj, const_val, \n",
    "               max_order_obj, max_order_const, upper_factor,\n",
    "               lower_factor, const_factor):\n",
    "\n",
    "    lamb = np.zeros( (X.shape[0], 1) )\n",
    "\n",
    "    baseline_util, _, _, _, _ = get_utility(X, GC_Const, GC_Obj, const_val, max_order_obj = max_order_obj, \n",
    "                                            max_order_const = max_order_const, upper_factor = upper_factor, \n",
    "                                            lower_factor = lower_factor, const_factor = const_factor)\n",
    "    #print(\"baseline_util =\", baseline_util)\n",
    "    #remaining_X = X\n",
    "    #for i in np.arange(10): #np.arange(0.1, 1.1, 0.1)[::-1]:\n",
    "    for i in np.arange(-2.0, 2.0, 0.15):\n",
    "\n",
    "        #new_X = (X + 2.**(-i * 1.) * dx).clip(0,1)\n",
    "        new_X = (X + i * dx).clip(0,1)\n",
    "        if True: #(new_X < 1.).all() and (new_X > 0.).all():            \n",
    "            temp_util, _, _, _, _ = get_utility(new_X, GC_Const, GC_Obj, const_val, max_order_obj = max_order_obj, \n",
    "                                                max_order_const = max_order_const, upper_factor = upper_factor, \n",
    "                                                lower_factor = lower_factor, const_factor = const_factor)\n",
    "            #lamb += 2.**(-i * 1.) * (temp_util<baseline_util).reshape((-1,1)) * (lamb == 0)\n",
    "            lamb += i * (temp_util<baseline_util).reshape((-1,1)) * (lamb == 0)\n",
    "        #print(lamb, temp_util)\n",
    "    #lamb += 2.**(-10.) * (lamb == 0)\n",
    "    lamb += 0.01 * (lamb == 0)\n",
    "    return lamb\n",
    "\n",
    "\n",
    "\n",
    "def get_obj_deriv(GC, X, max_order_obj):\n",
    "    num_vars = len(GC)\n",
    "\n",
    "    H   = get_orthogonal_polynomial(X, max_order_obj)\n",
    "    dH  = get_dH(X, max_order_obj)        \n",
    "    d2H = get_d2H(X, max_order_obj)\n",
    "    #dH = get_dH(H, max_order)\n",
    "    #d2H = get_d2H(dH, max_order)\n",
    "\n",
    "\n",
    "\n",
    "    #for i in range(num_vars):\n",
    "    #    H_modified = H.copy()\n",
    "    #    H_modified[:,i,:] = dH[:,i,:]\n",
    "    #    jac[:,i] = evaluate_tt_on_grid(GC, H_modified)\n",
    "    # Just moved this functionality into the first loop of the hessian computation\n",
    "    func = evaluate_tt_on_grid(GC, H)\n",
    "\n",
    "    jac = np.zeros(X.shape)\n",
    "    hess = np.zeros((H.shape[0], num_vars, num_vars))\n",
    "    for i in range(num_vars):\n",
    "        #print(i)\n",
    "\n",
    "        H_modified = H.copy() * 1.0\n",
    "        H_modified[:,i,:] = dH[:,i,:]\n",
    "        jac[:,i] = evaluate_tt_on_grid(GC, H_modified)\n",
    "\n",
    "        H_modified = H.copy()  * 1.0\n",
    "        H_modified[:,i,:] = d2H[:,i,:]\n",
    "        hess[:,i,i] = evaluate_tt_on_grid(GC, H_modified)\n",
    "\n",
    "        for j in range(i):\n",
    "            H_modified = H.copy()  * 1.0\n",
    "            H_modified[:,i,:] = dH[:,i,:]\n",
    "            H_modified[:,j,:] = dH[:,j,:]\n",
    "            #print(\"EVAL\")\n",
    "            hess_vals = evaluate_tt_on_grid(GC, H_modified)\n",
    "            #print(\"EVAL DONE\")\n",
    "            hess[:,i,j] = hess_vals\n",
    "            hess[:,j,i] = hess_vals\n",
    "\n",
    "    if False:\n",
    "        for i in range(X.shape[0]):\n",
    "            dx = np.linalg.solve(hess[i], jac[i])\n",
    "            for lam in np.arange(0.1, 1, 0.1):\n",
    "                x = X[i] - lam * dx\n",
    "                H = get_orthogonal_polynomial(x[None], max_order_obj)\n",
    "                func_new = evaluate_tt_on_grid(GC, H)\n",
    "                print(lam.round(2), func.round(2), func_new.round(2))\n",
    "    #print(jac)\n",
    "    #print(hess)\n",
    "    #blBL\n",
    "    return jac, hess\n",
    "\n",
    "def get_bounds_deriv(X, upper_factor, lower_factor):\n",
    "\n",
    "    num_points, num_vars = X.shape\n",
    "\n",
    "    #upper_bound = np.exp(-X/factor)\n",
    "    #lower_bound = np.exp( (X-1)/factor )\n",
    "\n",
    "    lower_bound_jac = - np.exp(-X/lower_factor) / lower_factor\n",
    "    upper_bound_jac = np.exp( (X-1)/upper_factor ) / upper_factor\n",
    "\n",
    "    combined_jac = lower_bound_jac + upper_bound_jac\n",
    "\n",
    "    \"\"\"\n",
    "    ABOVE IS GOOD\n",
    "    \"\"\"\n",
    "\n",
    "    lower_bound_hess = np.zeros((num_points,num_vars,num_vars))\n",
    "    upper_bound_hess = np.zeros((num_points,num_vars,num_vars))\n",
    "    for i in range(num_points):\n",
    "        lower_bound_hess[i] = np.diag(np.exp(-X[i]/lower_factor) / lower_factor**2.)\n",
    "        upper_bound_hess[i] = np.diag(np.exp((X[i]-1.)/upper_factor) / upper_factor**2.)\n",
    "\n",
    "    #lower_bound_hess[:,:,:] = np.eye(num_vars)[None,:,:]\n",
    "    #lower_bound_hess = lower_bound_hess * np.exp(-X/lower_factor)[:, :, None] / lower_factor**2\n",
    "\n",
    "    #upper_bound_hess[:,:,:] = np.eye(num_vars)[None,:,:]\n",
    "    #upper_bound_hess = upper_bound_hess * np.exp( (X-1)/upper_factor )[:, :, None]/ upper_factor**2\n",
    "\n",
    "    combined_hess = lower_bound_hess + upper_bound_hess\n",
    "\n",
    "\n",
    "    return combined_jac, combined_hess\n",
    "\n",
    "\n",
    "def get_const_deriv(GC, X, const_val, max_order_const, const_factor):\n",
    "\n",
    "    H = get_orthogonal_polynomial(X, max_order_const)\n",
    "    #dH = get_dH(H, max_order)\n",
    "    #d2H = get_d2H(dH, max_order)\n",
    "    dH = get_dH(X, max_order_const)\n",
    "    d2H = get_d2H(X, max_order_const)\n",
    "\n",
    "    num_vars = len(GC)\n",
    "\n",
    "    fx = evaluate_tt_on_grid(GC, H)\n",
    "    E = np.exp( (fx-const_val)/ const_factor )\n",
    "    #print(E, E.max(), E.min())\n",
    "    #print(\"Cost Penalty:\", E)\n",
    "\n",
    "    jac_complex = np.zeros(X.shape)\n",
    "    #for i in range(num_vars):\n",
    "    #    H_modified = H.copy()\n",
    "    #    H_modified[:,i,:] = dH[:,i,:]\n",
    "    #    jac_complex[:,i] = evaluate_tt_on_grid(GC, H_modified)\n",
    "    # moved functionality into first hessian loop\n",
    "\n",
    "\n",
    "    # H.shape[0] number of random samples\n",
    "    hess_complex = np.zeros((H.shape[0], num_vars, num_vars))\n",
    "\n",
    "    # computes the jacobian and Hessian of the const function        \n",
    "    for i in range(num_vars):\n",
    "        H_modified = H.copy()\n",
    "        H_modified[:,i,:] = dH[:,i,:]\n",
    "        jac_complex[:,i] = evaluate_tt_on_grid(GC, H_modified)\n",
    "        #print(i)\n",
    "        for j in range(i):\n",
    "            H_modified = H.copy()\n",
    "            H_modified[:,i,:] = dH[:,i,:]               \n",
    "            d1 = evaluate_tt_on_grid(GC, H_modified)\n",
    "\n",
    "            H_modified = H.copy()\n",
    "            H_modified[:,j,:] = dH[:,j,:]\n",
    "            d2 = evaluate_tt_on_grid(GC, H_modified)\n",
    "            H_modified[:,i,:] = dH[:,i,:]\n",
    "            hess_vals = evaluate_tt_on_grid(GC, H_modified)\n",
    "\n",
    "            #print(\"EVAL DONE\")\n",
    "            hess_complex[:,i,j] = hess_vals + d1 * d2 / const_factor\n",
    "            hess_complex[:,j,i] = hess_vals + d1 * d2 / const_factor\n",
    "\n",
    "\n",
    "\n",
    "        H_modified = H.copy()\n",
    "        H_modified[:,i,:] = dH[:,i,:]\n",
    "\n",
    "        squared_term = evaluate_tt_on_grid(GC, H_modified)**2 / const_factor\n",
    "\n",
    "        H_modified[:,i,:] = d2H[:,i,:]\n",
    "        hess_complex[:,i,i] = evaluate_tt_on_grid(GC, H_modified) + squared_term\n",
    "\n",
    "    jac_complex  *= E.reshape(-1,1)  /const_factor\n",
    "    hess_complex *= E.reshape(-1,1,1)/const_factor\n",
    "\n",
    "    return jac_complex, hess_complex\n",
    "\n",
    "    \n",
    "def gradient_optimize_tt(GC_Const, GC_Obj, n = 1, const_val = 3e6, max_order_obj = 4, \n",
    "                         max_order_const=4, upper_factor = 0.01, lower_factor = 0.01,\n",
    "                         const_factor = 1e4):\n",
    "\n",
    "    X = np.random.rand(n, len(GC_Const)) * 0.6 + 0.2\n",
    "    \n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(200):\n",
    "        #jac, hess = get_jac(GC_Obj, X, max_order)\n",
    "        #print(\"JAC\")\n",
    "        #hess = get_hess(GC_Obj, X, max_order)\n",
    "        #print(\"HESS\")\n",
    "        obj_jac, obj_hess = get_obj_deriv(GC_Obj, X, max_order_obj)\n",
    "        const_jac, const_hess = get_const_deriv(GC_Const, X, const_val, max_order_const = max_order_const, \n",
    "                                                        const_factor = const_factor)\n",
    "        boundary_jac, boundary_hess = get_bounds_deriv(X, upper_factor, lower_factor)\n",
    "\n",
    "        total_jac = 1.0*obj_jac + 1.0*const_jac + 1e2 * boundary_jac + 0e1 * 2. * (X - 0.5)\n",
    "        total_hess = 1.0*obj_hess + 1.0*const_hess + 1e2 * boundary_hess + 0e1 * 2. * np.eye(X.shape[1])[None]\n",
    "        dx = np.zeros(X.shape)\n",
    "        for j in range(X.shape[0]):\n",
    "            #dx[j] = - np.linalg.solve(np.diag(np.diag(total_hess[j])), total_jac[j])\n",
    "            dx[j] = - np.linalg.solve(total_hess[j], total_jac[j])\n",
    "        \n",
    "        X0 = X.copy()\n",
    "        lamb = linesearch(X0, dx, GC_Const, GC_Obj, const_val, max_order_obj = max_order_obj, \n",
    "                          max_order_const = max_order_const, upper_factor = upper_factor, \n",
    "                          lower_factor = lower_factor, const_factor = const_factor)\n",
    "        \n",
    "        #H = tt.get_orthogonal_polynomial(X0, max_order)\n",
    "        print(\"Lambda:\", lamb)\n",
    "        utility_x0, *_ = get_utility(X0, GC_Const, GC_Obj, const_val = const_val, max_order_obj = max_order_obj, \n",
    "                                     max_order_const = max_order_const, upper_factor = upper_factor, \n",
    "                                     lower_factor = lower_factor, const_factor = const_factor) \n",
    "        print(\"utility @ x0:\", utility_x0)\n",
    "        #print(evaluate_tt_on_grid(GC_Obj, H))\n",
    "\n",
    "        X += lamb * dx\n",
    "        X = X.clip(0,1)\n",
    "        #print(\"Params:\", X.round(2))\n",
    "\n",
    "        #H = tt.get_orthogonal_polynomial(X, max_order)\n",
    "        utility_x, obj, const_penalty, upper_bound, lower_bound = get_utility(X, GC_Const, \n",
    "                           GC_Obj, const_val = const_val, max_order_obj = max_order_obj, \n",
    "                           max_order_const = max_order_const, upper_factor = upper_factor, \n",
    "                           lower_factor = lower_factor, const_factor = const_factor)\n",
    "        print(\"utility @ x:\", utility_x)\n",
    "        print(\"obj @ x:\", obj)\n",
    "        print(\"const @ x\", const_penalty)\n",
    "        print(\"upper/lower: \", upper_bound + lower_bound)\n",
    "        perc_dx = (np.linalg.norm(X-X0)/np.linalg.norm(X0)*100)\n",
    "        if perc_dx < 0.1:\n",
    "            counter = counter + 1.\n",
    "        else:\n",
    "            counter = 0\n",
    "        if counter == 5:\n",
    "            break\n",
    "        \n",
    "        print(i, (np.linalg.norm(X-X0)/np.linalg.norm(X0)*100).round(2))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2e51d5",
   "metadata": {},
   "source": [
    "# this is the random obtimizer (No Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485171e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_optimize_tt(GC_Const, GC_Obj, const_val, max_order_obj = 4, max_order_const = 4, \n",
    "                         num_iters = 1, num_search = 10, xopt = None, to_select = 100):\n",
    "    Xselected = None\n",
    "    Y_Obj_opt = 30000\n",
    "    assert num_iters == 1\n",
    "    for k in range(num_iters):\n",
    "        #X = np.random.rand(int(100000/num_iters), len(GC_Const))\n",
    "        X = np.random.rand(100000, len(GC_Const))\n",
    "        if xopt is not None:\n",
    "            M = xopt.shape[0]\n",
    "            assert X.shape[1] == xopt.shape[1]\n",
    "            X[:M] = xopt\n",
    "        for iloop in range(50):  \n",
    "            # compute objective given set of points\n",
    "            H_obj = get_orthogonal_polynomial(X, max_order_obj)\n",
    "            Y_Obj = evaluate_tt_on_grid(GC_Obj, H_obj)\n",
    "            #print(\"In Optimization\", iloop, Y_Obj.min().round(2),Y_Obj.max().round(2),)\n",
    "            # compute constraints given set of points\n",
    "            H_const = get_orthogonal_polynomial(X, max_order_const)\n",
    "            Y_Const = evaluate_tt_on_grid(GC_Const, H_const)\n",
    "     \n",
    "            myCondition = Y_Const < const_val\n",
    "            S = np.argsort(Y_Obj[myCondition])\n",
    "            N = len(S)\n",
    "            Y_Obj_opt = Y_Obj[S[0]]\n",
    "\n",
    "            S = S[:to_select] # we chose the best performing half of the points\n",
    "            Xselected = (X[myCondition][S])\n",
    "            \n",
    "            for j in range(len(Xselected)):\n",
    "                X = (0.2 * np.random.rand(to_select,1)) * (np.random.rand(to_select, len(GC_Const))-0.5)\n",
    "                X[0] = Xselected[j]\n",
    "                X[1:] = X[1:] + Xselected[j]\n",
    "                X = X.clip(0,1)\n",
    "\n",
    "                # compute objective given set of points\n",
    "                H_obj_temp = get_orthogonal_polynomial(X, max_order_obj)\n",
    "                Y_Obj_temp = evaluate_tt_on_grid(GC_Obj, H_obj_temp)\n",
    "                # compute constraints given set of points\n",
    "                H_const_temp = get_orthogonal_polynomial(X, max_order_const)\n",
    "                Y_Const_temp = evaluate_tt_on_grid(GC_Const, H_const_temp)\n",
    "                \n",
    "                best = np.argsort(Y_Obj_temp[Y_Const_temp < const_val])\n",
    "                #print(Y_Obj_temp[Y_Const_temp < const_val][best])\n",
    "                #blabla\n",
    "                Xselected[j] = X[Y_Const_temp < const_val][best[0]]\n",
    "            X = Xselected\n",
    "                \n",
    "    H_obj = get_orthogonal_polynomial(Xselected, max_order_obj)\n",
    "    H_const = get_orthogonal_polynomial(Xselected, max_order_const)\n",
    "    Y_Const = evaluate_tt_on_grid(GC_Const, H_const)\n",
    "    Y_Obj = evaluate_tt_on_grid(GC_Obj, H_obj)\n",
    "    S = np.argsort(Y_Obj)\n",
    "\n",
    "    \n",
    "    #S = np.argsort(Y_Const < const_val)\n",
    "    return Xselected[S[:to_select]], Y_Obj[S[:to_select]], Y_Const[S[:to_select]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1453c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import model_generation as tt\n",
    "#import optimizers as optim\n",
    "\n",
    "def main_loop(const_name, obj_name, const_func, const_val, data_path, rank, max_order_obj, \n",
    "              max_order_const, numLoops, upper_factor, lower_factor, const_factor, \n",
    "              break_condition, num_iters, num_search, algo_type):\n",
    "    total_data = pd.read_csv(data_path)\n",
    "    cols = total_data.columns\n",
    "    main_loop_counter = 0\n",
    "    xopt = None\n",
    "    while True:\n",
    "        # for the toy example, the below line has no effect on\n",
    "        print(\"Main iteration\", main_loop_counter)\n",
    "        #print(\"Loadings data ...\")\n",
    "        #total_data = total_data.groupby(list(total_data.columns.values[:-2])).mean().reset_index()\n",
    "        print(\"Checking data size:\", total_data.shape)\n",
    "        # this part does the fitting\n",
    "        print(\"Computing TT models ...\")\n",
    "        GC_Const, tt_rank, Y, Y_estimated, W = main(const_name, total_data, max_order=max_order_const, \n",
    "                                                      initial_rank=rank, max_rank=rank, \n",
    "                                                      numLoops=numLoops)\n",
    "        print(\"Accuracy of the Constraint fit: Y, Y_Est, Diff\")\n",
    "        print(np.linalg.norm(Y).round(2), np.linalg.norm(Y_estimated).round(2), \n",
    "              np.linalg.norm(Y-Y_estimated).round(2))\n",
    "        print(\"Y_min, Y_max, Y_est_min, Y_est_max\")\n",
    "        print(Y.min(), Y.max(), Y_estimated.min(), Y_estimated.max())\n",
    "        \n",
    "        GC_Obj, tt_rank, Y, Y_estimated, W = main(obj_name, total_data, max_order=max_order_obj, \n",
    "                                                      initial_rank=rank, max_rank=rank, \n",
    "                                                      numLoops=numLoops)\n",
    "        print(\"Accuracy of the Obj fit: Y, Y_Est, Diff\")\n",
    "        print(np.linalg.norm(Y).round(2), np.linalg.norm(Y_estimated).round(2), \n",
    "              np.linalg.norm(Y-Y_estimated).round(2))\n",
    "        print(\"Y_min, Y_max, Y_est_min, Y_est_max\")\n",
    "        print(Y.min(), Y.max(), Y_estimated.min(), Y_estimated.max())\n",
    "        if algo_type == 'newton':\n",
    "            xopt = gradient_optimize_tt(GC_Const, GC_Obj, n = 1, const_val = const_val, \n",
    "                                        max_order_obj = max_order_obj, max_order_const = max_order_const, upper_factor = upper_factor,\n",
    "                                        lower_factor = lower_factor, const_factor = const_factor)\n",
    "            inputs, const, value = const_func(xopt)\n",
    "            #blah\n",
    "        elif algo_type == 'stochastic':\n",
    "            print(\"Optimizing ...\")\n",
    "            xopt, *_ = sampling_optimize_tt(GC_Const, GC_Obj, const_val, \n",
    "                                            max_order_obj = max_order_obj, \n",
    "                                            max_order_const = max_order_const, \n",
    "                                            num_iters = num_iters, num_search=num_search, \n",
    "                                            to_select = 100, xopt = xopt)\n",
    "            # inputs 1x num_vars: optimal\n",
    "            # const: scalar value of constraints at optimal\n",
    "            # value: scalar value of the objective at optimal\n",
    "            inputs, const, value = const_func(xopt)\n",
    "            \n",
    "        print(\"Optimized!\")\n",
    "\n",
    "        \n",
    "        print(\"ACTUAL VALUE:\", value.round(2))\n",
    "        # adds new data point to the dataframe\n",
    "        #new_frame = pd.DataFrame(data = np.array([*inputs, const, value]).reshape(1,-1), \n",
    "        #                         columns = cols)\n",
    "        # here is the data updated\n",
    "        print(\"Updating data ...\")\n",
    "        #total_data = pd.concat([total_data, new_frame])\n",
    "        cols=[f'x{i}' for i in range(num_vars)]+['obj', 'cost']\n",
    "        new_frame = pd.DataFrame(np.concatenate([inputs, value[:,None], const[:,None]], axis=1), columns=cols)\n",
    "        print(\"Augmenting Frame\", new_frame.round(2))\n",
    "        print(\"Data Adding!\", new_frame.shape)\n",
    "        total_data = pd.concat([total_data, new_frame], axis=0)\n",
    "        print(\"Data Augmenting!\", total_data.shape)        \n",
    "        total_data.to_csv(data_path, index = False)\n",
    "    \n",
    "        #print(\"Paramater Vals:\", xopt.round(2))\n",
    "        print(total_data.sort_values(obj_name)[:5])\n",
    "        if new_frame[const_name].values[0]>const_val:\n",
    "            print(\"Const Violation\")\n",
    "            continue\n",
    "        elif break_condition(const, value, total_data):\n",
    "            print(\"Optimization Done!\")\n",
    "            break\n",
    "        main_loop_counter = main_loop_counter + 1\n",
    "    total_data.to_csv(\"./final_data.csv\", index = False)\n",
    "    total_data.to_csv(data_path, index = False)\n",
    "    \n",
    "    print(xopt)\n",
    "    \n",
    "    \n",
    "\n",
    "def toy_func(x):\n",
    "    print(\"In Toy function/Showing DIMS\", x.shape)\n",
    "    obj_func = np.nansum((x-0.5)**2, axis=-1)\n",
    "    constraint_func = np.nansum(x, axis=-1)\n",
    "    return x, constraint_func, obj_func\n",
    "\n",
    "\n",
    "def my_break(const, obj, data):\n",
    "    return False\n",
    "    if const<1e7 and obj < 0.05:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def init_toy_problem(num_samples = 10000, num_vars = 30):\n",
    "    #cols = []\n",
    "    data_path = \"./dummy_func_30.csv\"\n",
    "    #data = pd.DataFrame(data = [], columns = cols)\n",
    "    #for i in range(30):\n",
    "    #    cols.append(\"x\"+str(i))\n",
    "    #cols.append(\"Const\")\n",
    "    #cols.append(\"Obj\")\n",
    "    X = np.random.rand(num_samples, num_vars)\n",
    "    obj = np.nansum((X - 0.5)**2, axis=-1)\n",
    "    cost = np.nansum(X, axis=-1)\n",
    "    cols=[f'x{i}' for i in range(num_vars)]+['obj', 'cost']\n",
    "    pd.DataFrame(np.concatenate((X, obj[:,None], cost[:,None]), axis=1), columns = cols).to_csv(\"./dummy_func_30.csv\", index = False)\n",
    "    #for i in range(100000):\n",
    "    #    inputs, const, value = toy_func(np.random.rand(30,))\n",
    "    #    new_frame = pd.DataFrame(data = np.array([*inputs, const, value]).reshape(1,-1), columns = cols)\n",
    "    #    data = pd.concat([data, new_frame], ignore_index = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "num_vars = 30\n",
    "init_toy_problem(num_samples, num_vars)\n",
    "inputs, const, value, total_data = main_loop(const_name=\"cost\", obj_name=\"obj\", const_func=toy_func, \n",
    "        const_val=30, data_path=\"./dummy_func_30.csv\", rank=4, max_order_obj=3, \n",
    "        max_order_const=4, numLoops=30, upper_factor=0.001, lower_factor=0.001, \n",
    "        const_factor=1e4, break_condition=my_break, num_iters = 1, num_search = 10, \n",
    "        algo_type = 'newton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e258047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols=[f'x{i}' for i in range(num_vars)]+['obj', 'cost']\n",
    "pd.concat([total_data, pd.DataFrame(np.concatenate([inputs, const[:,None], value[:,None]], axis=1), columns=cols)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b019059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK: 1\n",
      "Error on TRAINING: 1.8420467176995186\n",
      "Error on Testing: 1.8510808931277731\n",
      "RANK: 2\n",
      "Error on TRAINING: 1.797027270586795\n",
      "Error on Testing: 1.8356052475086178\n",
      "RANK: 3\n",
      "Error on TRAINING: 1.7604147421878429\n",
      "Error on Testing: 1.8391706116966433\n",
      "RANK: 4\n",
      "Error on TRAINING: 0.343307572362071\n",
      "Error on Testing: 0.38733852745769315\n",
      "RANK: 5\n",
      "Error on TRAINING: 0.2016612015539094\n",
      "Error on Testing: 0.22345578731228036\n",
      "RANK: 6\n",
      "Error on TRAINING: 0.12575608572882327\n",
      "Error on Testing: 0.13991723971714892\n",
      "RANK: 7\n",
      "Error on TRAINING: 0.10173945506000602\n",
      "Error on Testing: 0.11446725764256785\n",
      "RANK: 8\n",
      "Error on TRAINING: 0.06571952539139085\n",
      "Error on Testing: 0.0737515653179327\n",
      "RANK: 9\n",
      "Error on TRAINING: 0.06931159341944532\n",
      "Error on Testing: 0.07678912415030496\n",
      "RANK: 10\n",
      "Error on TRAINING: 0.04754344714743532\n",
      "Error on Testing: 0.05300069449245401\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "total_data = pd.read_csv(\"./dummy_func_30.csv\")\n",
    "test_data = pd.read_csv(\"./test_30.csv\")\n",
    "\n",
    "for rank in range(1, 11):\n",
    "    print(\"RANK:\", rank)\n",
    "    GC_Obj, tt_rank, Y, Y_estimated, W = main(\"obj\", total_data, max_order=3, \n",
    "                                                          initial_rank=rank, max_rank=rank, \n",
    "                                                          numLoops=50)\n",
    "\n",
    "    print(\"Error on TRAINING:\", np.linalg.norm(Y-Y_estimated)/np.linalg.norm(Y)*100)\n",
    "\n",
    "    X = test_data[test_data.columns[:-2].values].values\n",
    "    Y = test_data[\"obj\"].values\n",
    "    H = get_orthogonal_polynomial(X, 3)\n",
    "    Y_estimated = evaluate_tt_on_grid(GC_Obj, H)\n",
    "    print(\"Error on Testing:\", np.linalg.norm(Y-Y_estimated)/np.linalg.norm(Y)*100)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec4cfaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK: 1\n",
      "Error on TRAINING: 0.7591509955214436\n",
      "Error on Testing: 0.7855853871458075\n",
      "RANK: 2\n",
      "Error on TRAINING: 0.7135055880614108\n",
      "Error on Testing: 0.7449234330373578\n",
      "RANK: 3\n",
      "Error on TRAINING: 0.6954230549924346\n",
      "Error on Testing: 0.7335897817155688\n",
      "RANK: 4\n",
      "Error on TRAINING: 0.674327833299826\n",
      "Error on Testing: 0.7239160923017492\n",
      "RANK: 5\n",
      "Error on TRAINING: 0.6106946817569829\n",
      "Error on Testing: 0.6955714711974998\n",
      "RANK: 6\n",
      "Error on TRAINING: 0.18820955669659561\n",
      "Error on Testing: 0.23008847430154686\n",
      "RANK: 7\n",
      "Error on TRAINING: 0.10564335116954515\n",
      "Error on Testing: 0.12278511850444798\n",
      "RANK: 8\n",
      "Error on TRAINING: 0.09463262633570498\n",
      "Error on Testing: 0.11377246446155301\n",
      "RANK: 9\n",
      "Error on TRAINING: 0.09593066911252322\n",
      "Error on Testing: 0.11434454864684074\n",
      "RANK: 10\n",
      "Error on TRAINING: 0.04345256104894269\n",
      "Error on Testing: 0.05279403736112512\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "total_data = pd.read_csv(\"./dummy_func_30.csv\")\n",
    "test_data = pd.read_csv(\"./test_30.csv\")\n",
    "\n",
    "for rank in range(1, 11):\n",
    "    print(\"RANK:\", rank)\n",
    "    GC_Obj, tt_rank, Y, Y_estimated, W = main(\"cost\", total_data, max_order=4, \n",
    "                                                          initial_rank=rank, max_rank=rank, \n",
    "                                                          numLoops=50)\n",
    "\n",
    "    print(\"Error on TRAINING:\", np.linalg.norm(Y-Y_estimated)/np.linalg.norm(Y)*100)\n",
    "\n",
    "    X = test_data[test_data.columns[:-2].values].values\n",
    "    Y = test_data[\"cost\"].values\n",
    "    H = get_orthogonal_polynomial(X, 4)\n",
    "    Y_estimated = evaluate_tt_on_grid(GC_Obj, H)\n",
    "    print(\"Error on Testing:\", np.linalg.norm(Y-Y_estimated)/np.linalg.norm(Y)*100)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5a74337",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kb/h03r9hyd2k14d474g7_0z3500000gn/T/ipykernel_17211/366007835.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minit_toy_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/kb/h03r9hyd2k14d474g7_0z3500000gn/T/ipykernel_17211/2287579452.py\u001b[0m in \u001b[0;36minit_toy_problem\u001b[0;34m(num_samples, num_vars)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m#    data = pd.concat([data, new_frame], ignore_index = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "num_samples = 5000\n",
    "num_vars = 30\n",
    "init_toy_problem(num_samples, num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a07880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    num_samples = 50000\n",
    "    num_vars = 30\n",
    "    data_path = \"./test_30.csv\"\n",
    "    #data = pd.DataFrame(data = [], columns = cols)\n",
    "    #for i in range(30):\n",
    "    #    cols.append(\"x\"+str(i))\n",
    "    #cols.append(\"Const\")\n",
    "    #cols.append(\"Obj\")\n",
    "    X = np.random.rand(num_samples, num_vars)\n",
    "    obj = np.nansum((X - 0.5)**2, axis=-1)\n",
    "    cost = np.nansum(X, axis=-1)\n",
    "    cols=[f'x{i}' for i in range(num_vars)]+['obj', 'cost']\n",
    "    pd.DataFrame(np.concatenate((X, obj[:,None], cost[:,None]), axis=1), columns = cols).to_csv(\"./test_30.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df0c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2464198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
